{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# vAGI L-KAN train tren Modal.com (GPU A100 40GB)\n",
        "\n",
        "Notebook nay chay truc tiep trong Modal Notebook runtime da cap GPU A100 40GB.\n",
        "\n",
        "## Tham khao chinh\n",
        "- Modal GPU docs (A100): https://modal.com/docs/guide/gpu\n",
        "- Candle installation guide: https://huggingface.github.io/candle/guide/installation.html\n",
        "- Candle CUDA feature flags: https://docs.rs/crate/candle-core/0.8.4/features\n",
        "- TinyShakespeare corpus: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "## Output\n",
        "- Checkpoint duoc luu local trong notebook runtime de ban download.\n",
        "- Khong su dung thu vien `modal` Python SDK.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "import urllib.request\n",
        "\n",
        "def run(cmd: str, check: bool = True, cwd: pathlib.Path | None = None, env: dict | None = None):\n",
        "    print(f\"$ {cmd}\")\n",
        "    completed = subprocess.run(\n",
        "        cmd,\n",
        "        shell=True,\n",
        "        text=True,\n",
        "        capture_output=True,\n",
        "        cwd=str(cwd) if cwd else None,\n",
        "        env=env,\n",
        "    )\n",
        "    if completed.stdout:\n",
        "        print(completed.stdout)\n",
        "    if completed.stderr:\n",
        "        print(completed.stderr)\n",
        "    if check and completed.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed ({completed.returncode}): {cmd}\")\n",
        "    return completed\n",
        "\n",
        "print(\"Python:\", sys.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "REPO_URL = \"https://github.com/vietrix/vagi.git\"\n",
        "BRANCH = \"main\"\n",
        "WORKDIR = pathlib.Path(\"/root/vagi\")\n",
        "\n",
        "DATA_URL = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "DATA_PATH = WORKDIR / \"data\" / \"input.txt\"\n",
        "\n",
        "TRAIN_STEPS = 5_000\n",
        "BATCH_SIZE = 32\n",
        "SEQ_LEN = 64\n",
        "OUTPUT_CONST_PATH = \"models/lkan-genesis.safetensors\"\n",
        "\n",
        "EXPORT_DIR = pathlib.Path(\"/root/outputs\")\n",
        "EXPORT_NAME = \"lkan-genesis-a10040gb.safetensors\"\n",
        "\n",
        "print(\"Repo:\", REPO_URL)\n",
        "print(\"Branch:\", BRANCH)\n",
        "print(\"Workdir:\", WORKDIR)\n",
        "print(\"Dataset:\", DATA_PATH)\n",
        "print(\"Train steps:\", TRAIN_STEPS, \"batch:\", BATCH_SIZE, \"seq_len:\", SEQ_LEN)\n",
        "print(\"Output const path:\", OUTPUT_CONST_PATH)\n",
        "print(\"Export file:\", EXPORT_DIR / EXPORT_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpu = run(\"nvidia-smi\", check=False)\n",
        "if gpu.returncode != 0:\n",
        "    raise RuntimeError(\n",
        "        \"Khong tim thay GPU trong runtime hien tai. Hay chay notebook nay tren Modal runtime co A100 40GB.\"\n",
        "    )\n",
        "\n",
        "run(\"which nvcc\", check=False)\n",
        "run(\"nvcc --version\", check=False)\n",
        "run(\"df -h\", check=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run(\"apt-get -y update\")\n",
        "run(\"apt-get -y install build-essential pkg-config libssl-dev curl git\")\n",
        "\n",
        "if not pathlib.Path(\"/root/.cargo/bin/rustup\").exists():\n",
        "    run(\"curl https://sh.rustup.rs -sSf | sh -s -- -y --profile minimal\")\n",
        "\n",
        "os.environ[\"PATH\"] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
        "run(\"rustup default stable\")\n",
        "run(\"rustc --version\")\n",
        "run(\"cargo --version\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if WORKDIR.exists():\n",
        "    print(\"Removing existing repo at\", WORKDIR)\n",
        "    shutil.rmtree(WORKDIR)\n",
        "\n",
        "run(f\"git clone --depth 1 --branch {BRANCH} {REPO_URL} {WORKDIR}\")\n",
        "run(\"git rev-parse --short HEAD\", cwd=WORKDIR)\n",
        "run(\"ls -la\", cwd=WORKDIR, check=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "if not DATA_PATH.exists():\n",
        "    print(\"Downloading dataset from\", DATA_URL)\n",
        "    urllib.request.urlretrieve(DATA_URL, DATA_PATH)\n",
        "\n",
        "print(\"Dataset:\", DATA_PATH)\n",
        "print(\"Size bytes:\", DATA_PATH.stat().st_size)\n",
        "preview = DATA_PATH.read_text(encoding=\"utf-8\", errors=\"ignore\")[:400]\n",
        "print(\"Preview:\\n\", preview)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replace_const(text: str, name: str, value: str, as_str: bool = False) -> str:\n",
        "    pattern = rf\"const {name}: [^=]+ = [^;]+;\"\n",
        "    repl = f\"const {name}: usize = {value};\"\n",
        "    if as_str:\n",
        "        repl = f\"const {name}: &str = \\\"{value}\\\";\"\n",
        "    updated, n = re.subn(pattern, repl, text, count=1)\n",
        "    if n == 0:\n",
        "        raise RuntimeError(f\"Cannot find const {name} in train_lkan.rs\")\n",
        "    return updated\n",
        "\n",
        "kernel_cargo = WORKDIR / \"kernel\" / \"Cargo.toml\"\n",
        "cargo_text = kernel_cargo.read_text(encoding=\"utf-8\")\n",
        "m = re.search(r\"^candle-core\\s*=\\s*(.+)$\", cargo_text, flags=re.MULTILINE)\n",
        "if not m:\n",
        "    raise RuntimeError(\"Cannot find candle-core dependency\")\n",
        "current = m.group(0)\n",
        "if 'features = [\"cuda\"]' not in current:\n",
        "    vm = re.search(r\"version\\s*=\\s*\\\"([^\\\"]+)\\\"\", current) or re.search(r\"\\\"([^\\\"]+)\\\"\", current)\n",
        "    if not vm:\n",
        "        raise RuntimeError(f\"Cannot parse candle-core version from: {current}\")\n",
        "    version = vm.group(1)\n",
        "    newline = f\"candle-core = {{ version = \\\"{version}\\\", features = [\\\"cuda\\\"] }}\"\n",
        "    kernel_cargo.write_text(cargo_text.replace(current, newline), encoding=\"utf-8\")\n",
        "    print(\"Patched\", kernel_cargo)\n",
        "else:\n",
        "    print(\"candle-core already has cuda feature\")\n",
        "\n",
        "train_rs = WORKDIR / \"kernel\" / \"src\" / \"bin\" / \"train_lkan.rs\"\n",
        "train_src = train_rs.read_text(encoding=\"utf-8\")\n",
        "\n",
        "train_src = replace_const(train_src, \"OUTPUT_PATH\", OUTPUT_CONST_PATH, as_str=True)\n",
        "train_src = replace_const(train_src, \"TRAIN_STEPS\", str(TRAIN_STEPS))\n",
        "train_src = replace_const(train_src, \"BATCH_SIZE\", str(BATCH_SIZE))\n",
        "train_src = replace_const(train_src, \"SEQ_LEN\", str(SEQ_LEN))\n",
        "\n",
        "train_src = train_src.replace(\"hidden_dim: 192,\", \"hidden_dim: 128,\")\n",
        "train_src = train_src.replace(\"in_dim: 192,\", \"in_dim: 128,\")\n",
        "train_src = train_src.replace(\"out_dim: 192,\", \"out_dim: 128,\")\n",
        "\n",
        "if \"Device::new_cuda(0)\" not in train_src:\n",
        "    cpu_line = \"let device = Device::Cpu;\"\n",
        "    device_block = \"\"\"let device = match Device::new_cuda(0) {\n",
        "        Ok(dev) => {\n",
        "            println!(\\\"using CUDA device 0\\\");\n",
        "            dev\n",
        "        }\n",
        "        Err(err) => {\n",
        "            println!(\\\"CUDA unavailable ({err}), fallback to CPU\\\");\n",
        "            Device::Cpu\n",
        "        }\n",
        "    };\"\"\"\n",
        "    if cpu_line not in train_src:\n",
        "        raise RuntimeError(\"Cannot patch device selection block in train_lkan.rs\")\n",
        "    train_src = train_src.replace(cpu_line, device_block)\n",
        "\n",
        "train_rs.write_text(train_src, encoding=\"utf-8\")\n",
        "print(\"Patched\", train_rs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = os.environ.copy()\n",
        "env[\"PATH\"] = f\"/root/.cargo/bin:/usr/local/cuda/bin:{env.get('PATH', '')}\"\n",
        "env[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n",
        "env[\"LD_LIBRARY_PATH\"] = f\"/usr/local/cuda/lib64:{env.get('LD_LIBRARY_PATH', '')}\"\n",
        "\n",
        "run(\"rustc --version\", env=env)\n",
        "run(\"cargo --version\", env=env)\n",
        "run(\"cargo run -p vagi-kernel --release --bin train_lkan\", cwd=WORKDIR, env=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "candidates = [\n",
        "    WORKDIR / \"models\" / \"lkan-genesis.safetensors\",\n",
        "    WORKDIR / \"models\" / \"lkan-gen2.safetensors\",\n",
        "]\n",
        "checkpoint = next((p for p in candidates if p.exists()), None)\n",
        "if checkpoint is None:\n",
        "    raise FileNotFoundError(\"Training finished but no checkpoint found in models/\")\n",
        "\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "export_path = EXPORT_DIR / EXPORT_NAME\n",
        "shutil.copy2(checkpoint, export_path)\n",
        "\n",
        "print(\"Checkpoint source:\", checkpoint)\n",
        "print(\"Checkpoint exported:\", export_path)\n",
        "print(\"Size MB:\", round(export_path.stat().st_size / (1024 * 1024), 2))\n",
        "run(f\"sha256sum {export_path}\", check=False)\n",
        "print(\"Done. Download file tu\", export_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
